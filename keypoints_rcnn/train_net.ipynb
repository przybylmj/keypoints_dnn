{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core.model import Model, InferenceConfig \n",
    "from azureml.core import Workspace, Datastore, Experiment, Run, Environment, ScriptRunConfig\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, AksCompute\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.webservice import Webservice, AksWebservice, AciWebservice\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "print(f\"Azure ML version: {azureml.core.VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(f\"Workspace name:    {ws.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = ComputeTarget(ws,\"KeypointsCompute\")\n",
    "print(f\"Compute Target name:    {compute_target.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datastore.get_default(ws)\n",
    "print(f\"Datastore name:   {ds.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(ws,\"kp_exp\") \n",
    "print(f\"Experiment name:    {exp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.upload(src_dir=\"./data/\",target_path=\"kp_fixed_data\",overwrite=True,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_path = [(ds,\"kp_fixed_data/**\")]\n",
    "print(datastore_path)\n",
    "kp_dataset = Dataset.File.from_files(path=datastore_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New version of dataset to submit and use\n",
    "kp_dataset.register(workspace=ws,name=\"KeypointsData_v1\",description=\"Dataset with grasping keypoints\",create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to previous version of dataset\n",
    "# kp_dataset = Dataset.get_by_name(workspace=ws,name=\"KeypointsData_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"scripts/training_script.py\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pycocotools\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from utils import collate_fn\n",
    "import transforms, utils, engine, train\n",
    "from engine import train_one_epoch, evaluate\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "run = Run.get_context()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(f\"Device type:    {device}\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-folder\",type=str,dest=\"data_folder\",help=\"path to folder with data\",default=\"\")\n",
    "parser.add_argument(\"--num-epochs\",type=int,dest=\"num_epochs\",help=\"number of epochs to train model\",default=30)\n",
    "\n",
    "args = parser.parse_args()\n",
    "data_folder_path = args.data_folder \n",
    "num_epochs = args.num_epochs\n",
    "\n",
    "\n",
    "class ObjectsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,ds_root,ann_file,transform=None):\n",
    "        self.ds_root=ds_root\n",
    "        self.ann_file=ann_file\n",
    "        self.raw_coco_ds=torchvision.datasets.CocoDetection(self.ds_root,self.ann_file)\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image=self.raw_coco_ds[idx][0]\n",
    "        boxes,labels,image_id,area,iscrowd,keypoints=[],[],[],[],[],[]\n",
    "        image_id.append(self.raw_coco_ds[idx][1][0]['image_id'])\n",
    "        for item_id, item in enumerate(self.raw_coco_ds[idx][1]):\n",
    "            bbox_xywh=item['bbox']\n",
    "            boxes.append([bbox_xywh[0], bbox_xywh[1],bbox_xywh[0] + bbox_xywh[2],bbox_xywh[1] + bbox_xywh[3]])\n",
    "            labels.append(item['category_id'])\n",
    "            area.append(item['area'])\n",
    "            iscrowd.append(item['iscrowd'])\n",
    "            raw_keypoints=self.raw_coco_ds[idx][1][item_id]['keypoints']\n",
    "            kps=[]\n",
    "            for i in range(0,len(raw_keypoints),3):\n",
    "                kp=[]\n",
    "                kp.append(raw_keypoints[i])\n",
    "                kp.append(raw_keypoints[i+1])\n",
    "                if raw_keypoints[i+2] > 1:\n",
    "                    kp.append(1)\n",
    "                else:\n",
    "                    kp.append(raw_keypoints[i+2])\n",
    "                kps.append(kp)\n",
    "            keypoints.append(kps)   \n",
    "        image=torchvision.transforms.functional.to_tensor(image)\n",
    "        target={}\n",
    "        target['boxes'] = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels,dtype=torch.int64)\n",
    "        target['image_id'] = torch.as_tensor(image_id, dtype=torch.int64)\n",
    "        target['area'] = torch.as_tensor(area,dtype=torch.float32)\n",
    "        target['iscrowd'] = torch.as_tensor(iscrowd,dtype=torch.int64)\n",
    "        target['keypoints'] = torch.as_tensor(keypoints,dtype=torch.float32)\n",
    "\n",
    "        return image, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raw_coco_ds)\n",
    "\n",
    "def get_keypoints_model():\n",
    "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
    "    model=torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,pretrained_backbone=True,num_keypoints=1,num_classes=7,rpn_anchor_generator=anchor_generator)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "\n",
    "    dataset_train_root=os.path.join(data_folder_path,\"train_images\")\n",
    "    ann_train_file=os.path.join(data_folder_path,\"img_train_ann.json\")\n",
    "    dataset_test_root=os.path.join(data_folder_path,\"test_images\")\n",
    "    ann_test_file=os.path.join(data_folder_path,\"img_test_ann.json\")\n",
    "    dataset_train = ObjectsDataset(dataset_train_root,ann_train_file)\n",
    "    dataset_test = ObjectsDataset(dataset_test_root,ann_test_file)\n",
    "\n",
    "    dataset_train_loader=torch.utils.data.DataLoader(dataset_train,batch_size=6,shuffle=True,num_workers=8,collate_fn=collate_fn)\n",
    "    dataset_test_loader=torch.utils.data.DataLoader(dataset_test,batch_size=2,shuffle=False,num_workers=8,collate_fn=collate_fn)\n",
    "\n",
    "    model=get_keypoints_model()\n",
    "    model.to(device)\n",
    "    params=[p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.3)\n",
    "    # num_epochs = num_epochs + 1\n",
    "\n",
    "    for epoch in range(1,num_epochs + 1):\n",
    "        train_one_epoch(model,optimizer,dataset_train_loader,device,epoch,print_freq=10)\n",
    "        lr_scheduler.step()\n",
    "        evaluate(model,dataset_test_loader,device)    \n",
    "        if epoch % 5 == 0 and epoch >=10:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict()\n",
    "            },os.path.join('./outputs',f'checkpoint_epoch{epoch}.pth'))\n",
    "\n",
    "    torch.save(model,'./outputs/kp_model.pth')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\"--data-folder\",kp_dataset.as_named_input(\"keypoints_ds\").as_mount(),\"--num-epochs\",40]\n",
    "print(args)\n",
    "\n",
    "scripts_dir = \"./scripts/\"\n",
    "\n",
    "# default_env = Environment.get(ws,'AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu')\n",
    "env = Environment.get(ws,\"kp_env\")\n",
    "\n",
    "config = ScriptRunConfig(source_directory=scripts_dir,\n",
    "                            script=\"training_script.py\",\n",
    "                            compute_target=compute_target,\n",
    "                            environment=env,\n",
    "                            arguments=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_run = exp.submit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(exp_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_run.register_model(model_name=\"kp_model\",\n",
    "                            model_path=\"outputs\",\n",
    "                            model_framework=\"PyTorch\",\n",
    "                            model_framework_version=\"1.11\",\n",
    "                            description=\"Keypoint model for object grasping\")\n",
    "print(f\"Model name: {model.name}    model version:  {model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21e6572ebc00c11bbdc06f1073e9dc247b4c03fc2359025b3361dcdccdb999d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
